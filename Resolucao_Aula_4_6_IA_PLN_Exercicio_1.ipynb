{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resolucao - Aula 4-6 IA PLN - Exercicio 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/g-roger/natural-language-process/blob/main/Resolucao_Aula_4_6_IA_PLN_Exercicio_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPrDKODRFpdw"
      },
      "source": [
        "### **Exercício 1**\n",
        "\n",
        "###Que tal fazer isso com seu melhor modelo classificador de produtos?\n",
        "\n",
        "- Crie um pipeline produtivo do seu melhor modelo até aqui."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-DIEk-cFxB6"
      },
      "source": [
        "Carregamento dos dados e divisão dos dados entre amostras de Treino e Teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr_0G4MKETnd"
      },
      "source": [
        "# Pacotes utilizados\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Carga dos dados\n",
        "df = pd.read_csv(\"https://dados-ml-pln.s3-sa-east-1.amazonaws.com/produtos.csv\", delimiter=\";\", encoding='utf-8')\n",
        "\n",
        "# Limpeza da base de dados\n",
        "df.dropna(inplace=True)\n",
        "df[\"texto\"] = df['nome'] + \" \" + df['descricao']\n",
        "\n",
        "# Divisão das amostras em treino e teste\n",
        "df_treino, df_teste = train_test_split(\n",
        "      df, \n",
        "      test_size = 0.3, \n",
        "      random_state = 42\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuoQvNmshE6k"
      },
      "source": [
        "###**Parte 1: Pipeline de treinamento**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR3I_PZTGBNj"
      },
      "source": [
        "Instalação das dependências"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR_6Fh8dETiy"
      },
      "source": [
        "# Instalação do pacote SpaCy (se necessário)\n",
        "!pip install spacy\n",
        "!python -m spacy download pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx294AxXGFzZ"
      },
      "source": [
        "Preparação dos dados de **TREINO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4CJrca8ETgc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf820974-a403-45a3-f0e6-fad095202fa9"
      },
      "source": [
        "# Pacotes utilizados\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import spacy\n",
        "import nltk\n",
        "\n",
        "# Dependências do NLTK e do Spacy\n",
        "nltk.download('stopwords')\n",
        "nlp = spacy.load('pt')\n",
        "\n",
        "# Função de lematização para os verbos do documento\n",
        "def lemmatizer_verbs(text):\n",
        "  sent = []\n",
        "  doc = nlp(text)\n",
        "  for word in doc:\n",
        "      if word.pos_ == \"VERB\":\n",
        "          sent.append(word.lemma_)\n",
        "      else:\n",
        "          sent.append(word.text)\n",
        "  return \" \".join(sent)\n",
        "\n",
        "# Aplica a lematização no dataframe criando uma nova coluna\n",
        "df_treino['text_lemma_verbs'] = df_treino.texto.apply(lemmatizer_verbs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa9TLVl6GNIT"
      },
      "source": [
        "Vetorização dos dados de **TREINO** e Treinamento do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be4El8pRETdl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a4654b1-c99e-47d1-e7e5-45fdc35e4302"
      },
      "source": [
        "# Vetorização por contagem de termos simples com a combinação de unigrama e bigrama no documento com verbos lematizado, sem stopwords do SpaCy e NLTK combinadas e modelo de classificação DecisionTreeClassifier\n",
        "\n",
        "# Carrega as stopwords do SpaCy e NLTK combinadas\n",
        "stops = list(set(nlp.Defaults.stop_words).union(set(nltk.corpus.stopwords.words('portuguese'))))\n",
        "\n",
        "# vetorização por contagem de termos no documento com os verbos lematizado\n",
        "vect = CountVectorizer(ngram_range=(1,2), stop_words=stops) # vetorização por contagem de termos, combinação de unigrama e bigrama, remoção das stopwords NLTK e Spacy\n",
        "vect.fit(df_treino.text_lemma_verbs)\n",
        "text_vect_treino = vect.transform(df_treino.text_lemma_verbs)\n",
        "\n",
        "# treinamento do modelo ávore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(text_vect_treino, df_treino.categoria) # text_vect_treino: vetor com os dados de treino lematizado | df_treino.categoria: classificação real dos dados para o treinamento do modelo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=42, splitter='best')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVgU_EOZGQaJ"
      },
      "source": [
        "Salvando o vetor e o modelo treinado para reutilizar no pipeline produtivo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MFHof5IGRMc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c08966-fb85-4120-e2f3-78c651e8fca4"
      },
      "source": [
        "!ls -la"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 16\n",
            "drwxr-xr-x 1 root root 4096 Nov  1 13:35 .\n",
            "drwxr-xr-x 1 root root 4096 Nov 10 12:39 ..\n",
            "drwxr-xr-x 4 root root 4096 Nov  1 13:34 .config\n",
            "drwxr-xr-x 1 root root 4096 Nov  1 13:35 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J6DQq_tGRwE"
      },
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(tree, open('minha_arvore.pkl', 'wb'))\n",
        "pickle.dump(vect, open('meu_vetorizador.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PncLDGlnGRtn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7d5fa0a-2a71-4b28-dce2-6bf36d9b2c77"
      },
      "source": [
        "!ls -la"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 7884\n",
            "drwxr-xr-x 1 root root    4096 Nov 10 12:43 .\n",
            "drwxr-xr-x 1 root root    4096 Nov 10 12:39 ..\n",
            "drwxr-xr-x 4 root root    4096 Nov  1 13:34 .config\n",
            "-rw-r--r-- 1 root root 8034789 Nov 10 12:43 meu_vetorizador.pkl\n",
            "-rw-r--r-- 1 root root   17484 Nov 10 12:43 minha_arvore.pkl\n",
            "drwxr-xr-x 1 root root    4096 Nov  1 13:35 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYRBbPrqGXoD"
      },
      "source": [
        "###**Parte 2: Pipeline simulando um cenário produtivo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtuR9TS6GZJx"
      },
      "source": [
        "Preparação dos dados de **TESTE**, Vetorização e classificação com base no modelo treinado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHH1zAi5ETa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "879cc198-17c6-4f5a-9722-7f4f16e41331"
      },
      "source": [
        "# Pacotes utilizados nesse pipeline\n",
        "import spacy\n",
        "import nltk\n",
        "import pickle\n",
        "\n",
        "# Função de lematização para os verbos do documento\n",
        "def lemmatizer_verbs(text):\n",
        "  sent = []\n",
        "  doc = nlp(text)\n",
        "  for word in doc:\n",
        "      if word.pos_ == \"VERB\":\n",
        "          sent.append(word.lemma_)\n",
        "      else:\n",
        "          sent.append(word.text)\n",
        "  return \" \".join(sent)\n",
        "\n",
        "# Aplica a lematização no dataframe criando uma nova coluna\n",
        "df_teste['text_lemma_verbs'] = df_teste.texto.apply(lemmatizer_verbs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEIt8MLkGb-B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "3c50e2a9-4423-4692-f842-1cc128d3e1ed"
      },
      "source": [
        "# Carrega o vetor treinado\n",
        "meu_vetorizador = pickle.load(open('meu_vetorizador.pkl', 'rb'))\n",
        "\n",
        "# vetorização no dataframe de teste\n",
        "text_vect_teste = meu_vetorizador.transform(df_teste.text_lemma_verbs)\n",
        "\n",
        "# Carrega o modelo treinado\n",
        "minha_arvore = pickle.load(open('minha_arvore.pkl', 'rb'))\n",
        "\n",
        "# Escoragem da classificação na amostra de teste\n",
        "y_predicao = minha_arvore.predict(text_vect_teste)\n",
        "\n",
        "# Escoragem no dataframe\n",
        "df_teste['categoria_predita'] = y_predicao\n",
        "df_teste.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nome</th>\n",
              "      <th>descricao</th>\n",
              "      <th>categoria</th>\n",
              "      <th>texto</th>\n",
              "      <th>text_lemma_verbs</th>\n",
              "      <th>categoria_predita</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2700</th>\n",
              "      <td>Estojo Duo Iluminador E Bronzer Belle Angel M...</td>\n",
              "      <td>DUO ILUMINADOR E BRONZER BELLE ANGEL - B025O D...</td>\n",
              "      <td>maquiagem</td>\n",
              "      <td>Estojo Duo Iluminador E Bronzer Belle Angel M...</td>\n",
              "      <td>Estojo Duo Iluminador E Bronzer Belle Angel ...</td>\n",
              "      <td>maquiagem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1297</th>\n",
              "      <td>Patrulha Canina Carrinhos De Fricção 6 Person...</td>\n",
              "      <td>Kit carrinhos da Patrulha canina Tamanho: Cerc...</td>\n",
              "      <td>brinquedo</td>\n",
              "      <td>Patrulha Canina Carrinhos De Fricção 6 Person...</td>\n",
              "      <td>Patrulha Canina Carrinhos De Fricção 6 Perso...</td>\n",
              "      <td>brinquedo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3162</th>\n",
              "      <td>Pokemon Ultra Moon Nintendo 3ds Midia Fisica ...</td>\n",
              "      <td>#Nossos produtos são NOVOS e 100% ORIGINAIS#  ...</td>\n",
              "      <td>game</td>\n",
              "      <td>Pokemon Ultra Moon Nintendo 3ds Midia Fisica ...</td>\n",
              "      <td>Pokemon Ultra Moon Nintendo 3ds Midia Fisica...</td>\n",
              "      <td>game</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2895</th>\n",
              "      <td>Kite Pincel  12 Unidade</td>\n",
              "      <td>esta alta qualidade Punho de madeira Escova Co...</td>\n",
              "      <td>maquiagem</td>\n",
              "      <td>Kite Pincel  12 Unidade  esta alta qualidade ...</td>\n",
              "      <td>Kite Pincel   12 Unidade   esta alta qualida...</td>\n",
              "      <td>maquiagem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2226</th>\n",
              "      <td>Maleta Grande P/ Maquiagem Profissional Rodin...</td>\n",
              "      <td>FOTOS REAIS DO PRODUTO - ENVIAMOS SUA MALETA C...</td>\n",
              "      <td>maquiagem</td>\n",
              "      <td>Maleta Grande P/ Maquiagem Profissional Rodin...</td>\n",
              "      <td>Maleta Grande P/ Maquiagem Profissional Rodi...</td>\n",
              "      <td>maquiagem</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   nome  ... categoria_predita\n",
              "2700   Estojo Duo Iluminador E Bronzer Belle Angel M...  ...         maquiagem\n",
              "1297   Patrulha Canina Carrinhos De Fricção 6 Person...  ...         brinquedo\n",
              "3162   Pokemon Ultra Moon Nintendo 3ds Midia Fisica ...  ...              game\n",
              "2895                           Kite Pincel  12 Unidade   ...         maquiagem\n",
              "2226   Maleta Grande P/ Maquiagem Profissional Rodin...  ...         maquiagem\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW2NZwv2Gb79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "802d6eed-cb6c-4165-fc1d-9308865710d6"
      },
      "source": [
        "# Mensuração do resultado pela acurácia\n",
        "y_teste = df_teste.categoria\n",
        "accuracy = accuracy_score(y_predicao, y_teste)\n",
        "\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p9ghA-zPyM4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYoJ7eFXPyB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f9b92b1-1530-407e-f0bb-d601ca66d8c7"
      },
      "source": [
        "# Exemplo escoragem com um documento\n",
        "texto = 'Estojo Duo Iluminador E Bronzer'\n",
        "text_lemma = lemmatizer_verbs(texto)\n",
        "print(text_lemma)\n",
        "\n",
        "text_vect_teste = meu_vetorizador.transform([text_lemma])\n",
        "y_predicao = minha_arvore.predict(text_vect_teste)\n",
        "print(y_predicao)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estojo Duo Iluminador E Bronzer\n",
            "['maquiagem']\n"
          ]
        }
      ]
    }
  ]
}