{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula 2-6 IA PLN - Exercício.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/g-roger/natural-language-process/blob/main/Aula_2_6_IA_PLN_Exerc%C3%ADcio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2BT_ZwvhEKF"
      },
      "source": [
        "## Carregando o dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbxTY0CHaaDl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "adbcdb44-6566-4dd7-bc93-6f5867e5366b"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://dados-ml-pln.s3-sa-east-1.amazonaws.com/produtos.csv\", delimiter=\";\", encoding='utf-8')\n",
        "\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nome</th>\n",
              "      <th>descricao</th>\n",
              "      <th>categoria</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4080</td>\n",
              "      <td>2916</td>\n",
              "      <td>4080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>3696</td>\n",
              "      <td>2460</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Boneco Dragon Ball Z Son Gokou</td>\n",
              "      <td>JOGO ORIGINAL. NOVO. LACRADO. PRONTA ENTREGA. ...</td>\n",
              "      <td>brinquedo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>20</td>\n",
              "      <td>39</td>\n",
              "      <td>1020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     nome  ...  categoria\n",
              "count                                4080  ...       4080\n",
              "unique                               3696  ...          4\n",
              "top      Boneco Dragon Ball Z Son Gokou    ...  brinquedo\n",
              "freq                                   20  ...       1020\n",
              "\n",
              "[4 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNYOb9Z5kJm0"
      },
      "source": [
        "'''\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "# mostrar a estrutura de pastas do google drive montado\n",
        "!ls -la\n",
        "!ls -la gdrive/MyDrive/FIAP/NLP/dados\n",
        "\n",
        "# carrega dataframe do Google Drive\n",
        "df = pd.read_csv(\"gdrive/MyDrive/FIAP/NLP/dados/produtos.csv\", delimiter=\";\", encoding='utf-8')\n",
        "df = pd.read_csv(\"gdrive/MyDrive/<diretorio>/produtos.csv\", delimiter=\";\", encoding='utf-8')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzdJoltLsMnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f24d83e8-adcc-4cc8-8776-f28abf4d2ee1"
      },
      "source": [
        "df.dropna(inplace=True) # exclui registros com valores faltantes no própro objeto. inplace=False retorna uma cópia sem alterar o objeto.\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2916, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b1AsI8DhJN3"
      },
      "source": [
        "## Criar uma nova coluna Nome + Descrição"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0vbmpsTZ7w2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e138051d-2381-4d02-d51c-edfb4fbb5988"
      },
      "source": [
        "# Exemplo de concateção de informações\n",
        "print(\"Anderson\" + \"Dourado\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AndersonDourado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5naO2LQHb8c-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "201acc3f-3eb7-438a-bdd5-9d22b0c10078"
      },
      "source": [
        "df[\"texto\"] = df['nome'] + \" \" + df['descricao'] # cria uma nova culuna com os valores concatenados\n",
        "df.texto[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' O Hobbit - 7ª Ed. 2013  Produto NovoBilbo Bolseiro é um hobbit que leva uma vida confortável e sem ambições. Mas seu contentamento é perturbado quando Gandalf, o mago, e uma companhia de anões batem à sua porta e levam-no para uma expedição. Eles têm um plano para roubar o tesouro guardado por Smaug, o Magnífico, um grande e perigoso dragão. Bilbo reluta muito em participar da aventura, mas acaba surpreendendo até a si mesmo com sua esperteza e sua habilidade como ladrão!CaracterísticasAutor: Tolkien, J. R. R.Peso: 0.44I.S.B.N.: 9788578277109Altura: 20.000000Largura: 13.000000Profundidade: 1.000000Número de Páginas: 328Idioma: PortuguêsAcabamento: BrochuraNúmero da edição: 7Ano da edição: 2013'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eok0vq2diIFa"
      },
      "source": [
        "## Quantos Unigramas existem antes e depois de remover stopwords?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAz1ZRXwtag-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cebbbc1d-f440-433e-a96c-64a809244afb"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7EsxlE8gzY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "751b56fa-657c-4c15-faa9-3293c27f9cc9"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer # Converte uma coleção de documentos de texto em uma matriz de contagens de tokens\n",
        "\n",
        "vect = CountVectorizer(ngram_range=(1,1))\n",
        "vect.fit(df.texto)\n",
        "text_vect = vect.transform(df.texto)\n",
        "\n",
        "print('UNIGRAMAS com STOPWORDS', text_vect.shape[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UNIGRAMAS com STOPWORDS 35466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x39IfAib6DDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61271d7-4856-4698-bdb0-a18180667fe8"
      },
      "source": [
        "text_vect.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2916, 35466)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxswZwj1sXV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25d6486c-05bf-489b-ef17-87ad5219b90c"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "vect = CountVectorizer(ngram_range=(1,1), stop_words=stopwords)\n",
        "vect.fit(df.texto)\n",
        "text_vect = vect.transform(df.texto)\n",
        "\n",
        "print('UNIGRAMAS sem STOPWORDS', text_vect.shape[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UNIGRAMAS sem STOPWORDS 35310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTboWmwxtiXw"
      },
      "source": [
        "## Quantos Bigramas existem antes e depois de remover stopwords?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVWal6nhtlRE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0550b79f-24ff-4910-8259-7c19965ecce0"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vect = CountVectorizer(ngram_range=(2,2))\n",
        "vect.fit(df.texto)\n",
        "text_vect = vect.transform(df.texto)\n",
        "\n",
        "print('BIGRAMAS com STOPWORDS', text_vect.shape[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BIGRAMAS com STOPWORDS 159553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InldwDGxtlsd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c954fe94-0797-4516-a01d-8f7adcf7e389"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "vect = CountVectorizer(ngram_range=(2,2), stop_words=stopwords)\n",
        "vect.fit(df.texto)\n",
        "text_vect = vect.transform(df.texto)\n",
        "\n",
        "print('BIGRAMAS sem STOPWORDS', text_vect.shape[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BIGRAMAS sem STOPWORDS 145409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O85EfGNtzhN"
      },
      "source": [
        "## Quantos Trigramas existem antes e depois de remover stopwords?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM0puN6Jt67t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bfce035-5354-4207-c7d3-7343038483b9"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vect = CountVectorizer(ngram_range=(3,3))\n",
        "vect.fit(df.texto)\n",
        "text_vect = vect.transform(df.texto)\n",
        "\n",
        "print('TRIGRAMAS com STOPWORDS', text_vect.shape[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRIGRAMAS com STOPWORDS 228162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDfuZ3hht7Dh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8449bedd-dc59-4ba4-ec12-8ae116cc1caf"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "vect = CountVectorizer(ngram_range=(3,3), stop_words=stopwords)\n",
        "vect.fit(df.texto)\n",
        "text_vect = vect.transform(df.texto)\n",
        "\n",
        "print('TRIGRAMAS sem STOPWORDS', text_vect.shape[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRIGRAMAS sem STOPWORDS 177869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hUJ2U3nj1xt"
      },
      "source": [
        "## Quantos verbos e adverbios existem na nova coluna?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWpgtWG0vKS0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b9ef64f-f114-46ea-d63f-904ff1691bc0"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('universal_tagset')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij4J1taKd_DN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04ef82df-db0c-466d-aa8f-f5194088556e"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "word_tokenize('O Hobbit - 7ª Ed. 2013  Produto NovoBilbo Bolseiro é um hobbit que')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'Hobbit',\n",
              " '-',\n",
              " '7ª',\n",
              " 'Ed',\n",
              " '.',\n",
              " '2013',\n",
              " 'Produto',\n",
              " 'NovoBilbo',\n",
              " 'Bolseiro',\n",
              " 'é',\n",
              " 'um',\n",
              " 'hobbit',\n",
              " 'que']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Odl4b9aiOnA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "3934f23e-2901-4e49-f10e-a1d0224c450a"
      },
      "source": [
        "df['tokens'] = df.texto.apply(word_tokenize) # aplica a tokenização no campo texto\n",
        "\n",
        "df[[\"tokens\",\"texto\"]].head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>texto</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[O, Hobbit, -, 7ª, Ed, ., 2013, Produto, NovoB...</td>\n",
              "      <td>O Hobbit - 7ª Ed. 2013  Produto NovoBilbo Bol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Livro, -, It, A, Coisa, -, Stephen, King, Pro...</td>\n",
              "      <td>Livro - It A Coisa - Stephen King  Produto No...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              tokens                                              texto\n",
              "0  [O, Hobbit, -, 7ª, Ed, ., 2013, Produto, NovoB...   O Hobbit - 7ª Ed. 2013  Produto NovoBilbo Bol...\n",
              "1  [Livro, -, It, A, Coisa, -, Stephen, King, Pro...   Livro - It A Coisa - Stephen King  Produto No..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuyoJ0Gi1bGa"
      },
      "source": [
        "'''\n",
        "pd.set_option('display.max_colwidth', -1) # habilita a descrição completa do conteúdo das colunas\n",
        "df[[\"tokens\",\"texto\"]].head(2)\n",
        "pd.reset_option('display.max_colwidth')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohNe2lI6eBWv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9f06e61-4ff4-4e36-ca7e-8d9d7809fc79"
      },
      "source": [
        "from nltk.tag import pos_tag\n",
        "\n",
        "df['tags'] = df.tokens.apply(pos_tag, tagset='universal')\n",
        "\n",
        "df.tags.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [(O, NOUN), (Hobbit, NOUN), (-, .), (7ª, NUM),...\n",
              "1    [(Livro, NOUN), (-, .), (It, PRON), (A, DET), ...\n",
              "2    [(Box, NOUN), (As, ADP), (Crônicas, NOUN), (De...\n",
              "3    [(Box, NOUN), (Harry, NOUN), (Potter, NOUN), (...\n",
              "4    [(Livro, NOUN), (Origem, NOUN), (-, .), (Dan, ...\n",
              "Name: tags, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUZnYjJ7fLUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9f1c834-6c04-4e5c-da21-f8d0a841fe52"
      },
      "source": [
        "df.tags[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('O', 'NOUN'),\n",
              " ('Hobbit', 'NOUN'),\n",
              " ('-', '.'),\n",
              " ('7ª', 'NUM'),\n",
              " ('Ed', 'NOUN'),\n",
              " ('.', '.'),\n",
              " ('2013', 'NUM'),\n",
              " ('Produto', 'NOUN'),\n",
              " ('NovoBilbo', 'NOUN'),\n",
              " ('Bolseiro', 'NOUN'),\n",
              " ('é', 'NOUN'),\n",
              " ('um', 'ADJ'),\n",
              " ('hobbit', 'NOUN'),\n",
              " ('que', 'ADJ'),\n",
              " ('leva', 'NOUN'),\n",
              " ('uma', 'ADJ'),\n",
              " ('vida', 'NOUN'),\n",
              " ('confortável', 'NOUN'),\n",
              " ('e', 'NOUN'),\n",
              " ('sem', 'NOUN'),\n",
              " ('ambições', 'NOUN'),\n",
              " ('.', '.'),\n",
              " ('Mas', 'NOUN'),\n",
              " ('seu', 'VERB'),\n",
              " ('contentamento', 'ADJ'),\n",
              " ('é', 'NOUN'),\n",
              " ('perturbado', 'NOUN'),\n",
              " ('quando', 'NOUN'),\n",
              " ('Gandalf', 'NOUN'),\n",
              " (',', '.'),\n",
              " ('o', 'NOUN'),\n",
              " ('mago', 'NOUN'),\n",
              " (',', '.'),\n",
              " ('e', 'X'),\n",
              " ('uma', 'ADJ'),\n",
              " ('companhia', 'NOUN'),\n",
              " ('de', 'ADP'),\n",
              " ('anões', 'X'),\n",
              " ('batem', 'NOUN'),\n",
              " ('à', 'NOUN'),\n",
              " ('sua', 'NOUN'),\n",
              " ('porta', 'NOUN'),\n",
              " ('e', 'VERB'),\n",
              " ('levam-no', 'ADJ'),\n",
              " ('para', 'NOUN'),\n",
              " ('uma', 'ADJ'),\n",
              " ('expedição', 'NOUN'),\n",
              " ('.', '.'),\n",
              " ('Eles', 'NOUN'),\n",
              " ('têm', 'VERB'),\n",
              " ('um', 'ADJ'),\n",
              " ('plano', 'NOUN'),\n",
              " ('para', 'NOUN'),\n",
              " ('roubar', 'NOUN'),\n",
              " ('o', 'NOUN'),\n",
              " ('tesouro', 'NOUN'),\n",
              " ('guardado', 'NOUN'),\n",
              " ('por', 'NOUN'),\n",
              " ('Smaug', 'NOUN'),\n",
              " (',', '.'),\n",
              " ('o', 'NOUN'),\n",
              " ('Magnífico', 'NOUN'),\n",
              " (',', '.'),\n",
              " ('um', 'ADJ'),\n",
              " ('grande', 'NOUN'),\n",
              " ('e', 'NOUN'),\n",
              " ('perigoso', 'NOUN'),\n",
              " ('dragão', 'NOUN'),\n",
              " ('.', '.'),\n",
              " ('Bilbo', 'NOUN'),\n",
              " ('reluta', 'NOUN'),\n",
              " ('muito', 'NOUN'),\n",
              " ('em', 'NOUN'),\n",
              " ('participar', 'NOUN'),\n",
              " ('da', 'NOUN'),\n",
              " ('aventura', 'NOUN'),\n",
              " (',', '.'),\n",
              " ('mas', 'X'),\n",
              " ('acaba', 'X'),\n",
              " ('surpreendendo', 'X'),\n",
              " ('até', 'X'),\n",
              " ('a', 'DET'),\n",
              " ('si', 'NOUN'),\n",
              " ('mesmo', 'NOUN'),\n",
              " ('com', 'NOUN'),\n",
              " ('sua', 'NOUN'),\n",
              " ('esperteza', 'NOUN'),\n",
              " ('e', 'NOUN'),\n",
              " ('sua', 'NOUN'),\n",
              " ('habilidade', 'VERB'),\n",
              " ('como', 'ADJ'),\n",
              " ('ladrão', 'NOUN'),\n",
              " ('!', '.'),\n",
              " ('CaracterísticasAutor', 'NOUN'),\n",
              " (':', '.'),\n",
              " ('Tolkien', 'NOUN'),\n",
              " (',', '.'),\n",
              " ('J.', 'NOUN'),\n",
              " ('R.', 'NOUN'),\n",
              " ('R.Peso', 'NOUN'),\n",
              " (':', '.'),\n",
              " ('0.44I.S.B.N', 'NUM'),\n",
              " ('.', '.'),\n",
              " (':', '.'),\n",
              " ('9788578277109Altura', 'NUM'),\n",
              " (':', '.'),\n",
              " ('20.000000Largura', 'NUM'),\n",
              " (':', '.'),\n",
              " ('13.000000Profundidade', 'NUM'),\n",
              " (':', '.'),\n",
              " ('1.000000Número', 'NUM'),\n",
              " ('de', 'ADP'),\n",
              " ('Páginas', 'NOUN'),\n",
              " (':', '.'),\n",
              " ('328Idioma', 'NUM'),\n",
              " (':', '.'),\n",
              " ('PortuguêsAcabamento', 'NOUN'),\n",
              " (':', '.'),\n",
              " ('BrochuraNúmero', 'NOUN'),\n",
              " ('da', 'VERB'),\n",
              " ('edição', 'NOUN'),\n",
              " (':', '.'),\n",
              " ('7Ano', 'NUM'),\n",
              " ('da', 'NOUN'),\n",
              " ('edição', 'NOUN'),\n",
              " (':', '.'),\n",
              " ('2013', 'NUM')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dl5TtRpfvKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "744078f1-e304-40f6-aa9a-46c787b0543c"
      },
      "source": [
        "from collections import Counter\n",
        "counter = Counter()\n",
        "\n",
        "counter['a'] += 2\n",
        "counter\n",
        "\n",
        "counter.update('a')\n",
        "counter.update('b')\n",
        "counter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'a': 3, 'b': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiHuebNkKoNL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "627d4bc7-e8cf-4230-c42b-1e17820a344f"
      },
      "source": [
        "tags = df.tags[1]\n",
        "print(tags)\n",
        "print(\" \")\n",
        "\n",
        "for word, tag in tags[:5]:\n",
        "  print(\"word: \", word, \" tag: \", tag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Livro', 'NOUN'), ('-', '.'), ('It', 'PRON'), ('A', 'DET'), ('Coisa', 'NOUN'), ('-', '.'), ('Stephen', 'NOUN'), ('King', 'NOUN'), ('Produto', 'NOUN'), ('NovoDurante', 'NOUN'), ('as', 'ADP'), ('férias', 'ADJ'), ('escolares', 'NOUN'), ('de', 'ADP'), ('1958', 'NUM'), (',', '.'), ('em', 'X'), ('Derry', 'NOUN'), (',', '.'), ('pacata', 'NOUN'), ('cidadezinha', 'NOUN'), ('do', 'VERB'), ('Maine', 'NOUN'), (',', '.'), ('Bill', 'NOUN'), (',', '.'), ('Richie', 'NOUN'), (',', '.'), ('Stan', 'NOUN'), (',', '.'), ('Mike', 'NOUN'), (',', '.'), ('Eddie', 'NOUN'), (',', '.'), ('Ben', 'NOUN'), ('e', 'VERB'), ('Beverly', 'NOUN'), ('aprenderam', 'NOUN'), ('o', 'NOUN'), ('real', 'ADJ'), ('sentido', 'NOUN'), ('da', 'NOUN'), ('amizade', 'NOUN'), (',', '.'), ('do', 'VERB'), ('amor', 'ADV'), (',', '.'), ('da', 'NOUN'), ('confiança', 'NOUN'), ('e', 'NOUN'), ('...', '.'), ('do', 'VERB'), ('medo', 'NOUN'), ('.', '.'), ('O', 'NOUN'), ('mais', 'VERB'), ('profundo', 'ADJ'), ('e', 'NOUN'), ('tenebroso', 'NOUN'), ('medo', 'NOUN'), ('.', '.'), ('Naquele', 'NOUN'), ('verão', 'NOUN'), (',', '.'), ('eles', 'VERB'), ('enfrentaram', 'X'), ('pela', 'NOUN'), ('primeira', 'NOUN'), ('vez', 'VERB'), ('a', 'DET'), ('Coisa', 'NOUN'), (',', '.'), ('um', 'ADJ'), ('ser', 'NOUN'), ('sobrenatural', 'ADJ'), ('e', 'NOUN'), ('maligno', 'NOUN'), ('que', 'NOUN'), ('deixou', 'NOUN'), ('terríveis', 'NOUN'), ('marcas', 'NOUN'), ('de', 'ADP'), ('sangue', 'X'), ('em', 'NOUN'), ('Derry', 'NOUN'), ('.', '.'), ('Quase', 'NOUN'), ('trinta', 'ADJ'), ('anos', 'NOUN'), ('depois', 'NOUN'), (',', '.'), ('os', 'ADJ'), ('amigos', 'NOUN'), ('voltam', 'NOUN'), ('a', 'DET'), ('se', 'ADJ'), ('encontrar', 'NOUN'), ('.', '.'), ('Uma', 'NOUN'), ('nova', 'ADJ'), ('onda', 'NOUN'), ('de', 'ADP'), ('terror', 'NOUN'), ('tomou', 'VERB'), ('a', 'DET'), ('pequena', 'NOUN'), ('cidade', 'NOUN'), ('.', '.'), ('Mike', 'NOUN'), ('Hanlon', 'NOUN'), (',', '.'), ('o', 'ADJ'), ('único', 'NOUN'), ('que', 'NOUN'), ('permanece', 'NOUN'), ('em', 'NOUN'), ('Derry', 'NOUN'), (',', '.'), ('dá', 'NOUN'), ('o', 'ADJ'), ('sinal', 'ADJ'), ('.', '.'), ('Precisam', 'NOUN'), ('unir', 'ADJ'), ('forças', 'NOUN'), ('novamente', 'NOUN'), ('.', '.'), ('A', 'DET'), ('Coisa', 'NOUN'), ('volta', 'NOUN'), ('a', 'DET'), ('atacar', 'NOUN'), ('e', 'NOUN'), ('eles', 'NOUN'), ('devem', 'VERB'), ('cumprir', 'VERB'), ('a', 'DET'), ('promessa', 'NOUN'), ('selada', 'NOUN'), ('com', 'NOUN'), ('sangue', 'NOUN'), ('que', 'NOUN'), ('fizeram', 'NOUN'), ('quando', 'NOUN'), ('crianças', 'NOUN'), ('.', '.'), ('Só', 'NOUN'), ('eles', 'VERB'), ('têm', 'VERB'), ('a', 'DET'), ('chave', 'NOUN'), ('do', 'NOUN'), ('enigma', 'NOUN'), ('.', '.'), ('Só', 'NOUN'), ('eles', 'VERB'), ('sabem', 'X'), ('o', 'ADJ'), ('que', 'NOUN'), ('se', 'NOUN'), ('esconde', 'NOUN'), ('nas', 'NOUN'), ('entranhas', 'X'), ('de', 'X'), ('Derry', 'NOUN'), ('.', '.'), ('O', 'NOUN'), ('tempo', 'ADJ'), ('é', 'NOUN'), ('curto', 'NOUN'), (',', '.'), ('mas', 'X'), ('somente', 'NOUN'), ('eles', 'NOUN'), ('podem', 'VERB'), ('vencer', 'ADP'), ('a', 'DET'), ('Coisa', 'NOUN'), ('.', '.'), ('Em', 'NOUN'), ('``', '.'), ('It', 'PRON'), ('-', '.'), ('A', 'DET'), ('Coisa', 'NOUN'), (\"''\", '.'), (',', '.'), ('clássico', 'X'), ('de', 'X'), ('Stephen', 'NOUN'), ('King', 'NOUN'), ('em', 'NOUN'), ('nova', 'NOUN'), ('edição', 'NOUN'), (',', '.'), ('os', 'ADJ'), ('amigos', 'NOUN'), ('irão', 'NOUN'), ('até', 'NOUN'), ('o', 'NOUN'), ('fim', 'NOUN'), (',', '.'), ('mesmo', 'NOUN'), ('que', 'NOUN'), ('isso', 'NOUN'), ('signifique', 'NOUN'), ('ultrapassar', 'ADJ'), ('os', 'ADJ'), ('próprios', 'NOUN'), ('limites.CaracterísticasAutor', 'NOUN'), (':', '.'), ('King', 'NOUN'), (',', '.'), ('StephenPeso', 'NOUN'), (':', '.'), ('1.44I.S.B.N', 'NUM'), ('.', '.'), (':', '.'), ('9788560280940Altura', 'NUM'), (':', '.'), ('23.000000Largura', 'NUM'), (':', '.'), ('15.000000Profundidade', 'NUM'), (':', '.'), ('5.300000Idioma', 'NUM'), (':', '.'), ('PortuguêsAcabamento', 'NOUN'), (':', '.'), ('0Tradutor', 'NUM'), (':', '.'), ('Winarski', 'NOUN'), (',', '.'), ('RegianeNúmero', 'NOUN'), ('da', 'VERB'), ('edição', 'NOUN'), (':', '.'), ('0País', 'NUM'), ('de', 'ADP'), ('Origem', 'NOUN'), (':', '.'), ('BrasilSegmento', 'NOUN'), (':', '.'), ('Ficção', 'NOUN'), ('-', '.'), ('Histórias', 'NOUN'), ('inquietantes', 'VERB'), ('-', '.'), ('Terror', 'NOUN')]\n",
            " \n",
            "word:  Livro  tag:  NOUN\n",
            "word:  -  tag:  .\n",
            "word:  It  tag:  PRON\n",
            "word:  A  tag:  DET\n",
            "word:  Coisa  tag:  NOUN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12xzkR1zz3nC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50ff7587-2c1d-4a68-fabd-bb8da3af9a3f"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "counter = Counter()\n",
        "\n",
        "for tags in df.tags:\n",
        "  for word, tag in tags:\n",
        "    counter[tag] += 1\n",
        "\n",
        "print('Verbos', counter.get('VERB'))\n",
        "print('Adjetivos', counter.get('ADJ'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Verbos 41770\n",
            "Adjetivos 50788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLvw-MU-hSv4"
      },
      "source": [
        "'''\n",
        "# para quem quiser entender como funciona a lógica, segue a mesma lógica usando print para mapear os passos\n",
        "from collections import Counter\n",
        "counter = Counter()\n",
        "for tags in df.tags:\n",
        "  print(\"tags: \", tags)\n",
        "  for word, tag in tags:\n",
        "    counter[tag] += 1\n",
        "    print(\"word: \", word, \" tag: \", tag)\n",
        "print('Verbos', counter.get('VERB'))\n",
        "print('Adjetivos', counter.get('ADJ'))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kuPtf4ME7ks",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "867d62f0-3799-4fed-b23f-b67120586c7a"
      },
      "source": [
        "counter.get('NOUN') # SUBSTANTIVO"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "357181"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-w3pk50Ogl_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "634fa73b-d42b-4e33-b5b9-fc68517106f2"
      },
      "source": [
        "counter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'.': 89103,\n",
              "         'ADJ': 50788,\n",
              "         'ADP': 18205,\n",
              "         'ADV': 3652,\n",
              "         'CONJ': 1189,\n",
              "         'DET': 15421,\n",
              "         'NOUN': 357181,\n",
              "         'NUM': 24064,\n",
              "         'PRON': 282,\n",
              "         'PRT': 1824,\n",
              "         'VERB': 41770,\n",
              "         'X': 38967})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh60rZ8NIijA"
      },
      "source": [
        "De/Para do POS Tag com o tagset='universal':\n",
        "\n",
        "- NOUN (nouns / substantivos)\n",
        "- VERB (verbs / verbos)\n",
        "- ADJ (adjectives / adjetivos)\n",
        "- ADV (adverbs / advérbios)\n",
        "- PRON (pronouns / pronomes)\n",
        "- DET (determiners and articles / determinantes e artigos)\n",
        "- ADP (prepositions and postpositions / preposições e postposições)\n",
        "- NUM (numerals / numerais)\n",
        "- CONJ (conjunctions / conjunções)\n",
        "- PRT (particles / partículas)\n",
        "- . (punctuation marks / sinais de pontuação)\n",
        "- X (a catch-all for other categories such as abbreviations or foreign words / um exemplo geral para outras categorias, como abreviações ou palavras estrangeiras)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRICVTAt5F56"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVDjrt-eT4MV"
      },
      "source": [
        "## Aplicar Stemmer em uma frase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gqSkCwdUXbF"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"https://dados-ml-pln.s3-sa-east-1.amazonaws.com/produtos.csv\", delimiter=\";\", encoding='utf-8')\n",
        "\n",
        "df.info()\n",
        "df.dropna(inplace=True) # exclui registros com valores faltantes no própro objeto. inplace=False retorna uma cópia sem alterar o objeto.\n",
        "df.info()\n",
        "\n",
        "df[\"texto\"] = df['nome'] + \" \" + df['descricao'] # cria uma nova culuna com os valores concatenados\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "df['tokens'] = df.texto.apply(word_tokenize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBJ-oLU9T3jT"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.rslp import RSLPStemmer\n",
        "import nltk\n",
        "nltk.download('rslp')\n",
        "\n",
        "tokens = df.tokens[0]\n",
        "\n",
        "ps = PorterStemmer()\n",
        "rslp = RSLPStemmer()\n",
        "\n",
        "for tok in tokens:\n",
        "  print('PorterStemmer: %s \\t\\t RSLPStemmer: %s' % (ps.stem(tok), rslp.stem(tok)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhTMo3h0oFA7"
      },
      "source": [
        "## Quantos unigramas existem após aplicar Stemmer?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlUI2NgDhufq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfbcae89-92e9-4218-a8c7-4877824d51fe"
      },
      "source": [
        "', '.join(['Anderson', 'Dourado'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Anderson,Dourado'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_3LR9sO0hRm"
      },
      "source": [
        "from nltk.stem.rslp import RSLPStemmer\n",
        "import nltk\n",
        "nltk.download('rslp')\n",
        "\n",
        "rslp = RSLPStemmer()\n",
        "\n",
        "def stem_pandas(line):\n",
        "  return ' '.join([rslp.stem(token) for token in line])\n",
        "\n",
        "df['stemmer'] = df.tokens.apply(stem_pandas)\n",
        "\n",
        "df.stemmer.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFiA2cAORmpc"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "vect = CountVectorizer(ngram_range=(1,1), stop_words=stopwords)\n",
        "vect.fit(df.stemmer)\n",
        "\n",
        "text_vect = vect.transform(df.stemmer)\n",
        "\n",
        "print('UNIGRAMAS sem STOPWORDS', text_vect.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMtdbotJZxob"
      },
      "source": [
        "Comparando com o primeiro exercício => UNIGRAMAS sem STOPWORDS 35310"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QGwgdjvSW7L"
      },
      "source": [
        "NLTK = Natural Language Tool Kit\n",
        "\n",
        "RSLP = Removedor de Sulfixos da Língua Portuguesa\n"
      ]
    }
  ]
}